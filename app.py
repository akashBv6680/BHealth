# app.py
# HealthAI Suite - Intelligent Analytics for Patient Care

import streamlit as st
import os
import tempfile
import uuid
import numpy as np
import pandas as pd
import base64
from typing import List, Dict, Any
from io import BytesIO
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
import torch
from transformers import (
Â  Â  AutoTokenizer,
Â  Â  AutoModelForSequenceClassification,
Â  Â  AutoModel,
Â  Â  MarianMTModel,
Â  Â  MarianTokenizer,
)
import torchvision.transforms as T
from PIL import Image
from huggingface_hub import login as hf_login

# For association rules
try:
Â  Â  from mlxtend.frequent_patterns import apriori, association_rules
except ImportError:
Â  Â  apriori = None
Â  Â  association_rules = None
Â  Â  st.warning("mlxtend not found. Medical Associations module will not function.")

# For chat assistant
try:
Â  Â  import together
except ImportError:
Â  Â  together = None
Â  Â  st.warning("together not found. Chat Assistant module will not function.")

# -------------------------
# App config
# -------------------------
st.set_page_config(page_title="HealthAI Suite", page_icon="ðŸ©º", layout="wide")

# Hugging Face login
try:
Â  Â  # Use st.secrets to securely manage your Hugging Face token
Â  Â  if "HF_ACCESS_TOKEN" in st.secrets:
Â  Â  Â  Â  hf_login(token=st.secrets["HF_ACCESS_TOKEN"], add_to_git_credential=False)
Â  Â  else:
Â  Â  Â  Â  st.warning("Hugging Face access token not found in secrets.toml.")
except Exception as e:
Â  Â  st.error(f"Hugging Face login failed: {e}")

LANGUAGE_DICT = {
Â  Â  "English": "en", "Spanish": "es", "Arabic": "ar", "French": "fr", "German": "de", "Hindi": "hi",
Â  Â  "Tamil": "ta", "Bengali": "bn", "Japanese": "ja", "Korean": "ko", "Russian": "ru",
Â  Â  "Chinese (Simplified)": "zh-Hans", "Portuguese": "pt", "Italian": "it", "Dutch": "nl", "Turkish": "tr"
}

# -------------------------
# Helpers: safe model loaders (cached)
# -------------------------
@st.cache_resource(show_spinner=False)
def load_text_classifier(model_name="bhadresh-savani/bert-base-uncased-emotion"):
Â  Â  """Loads a text classification model."""
Â  Â  try:
Â  Â  Â  Â  tokenizer = AutoTokenizer.from_pretrained(model_name)
Â  Â  Â  Â  model = AutoModelForSequenceClassification.from_pretrained(model_name)
Â  Â  Â  Â  model.eval()
Â  Â  Â  Â  return tokenizer, model
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Failed to load text classifier model: {e}")
Â  Â  Â  Â  return None, None

@st.cache_resource(show_spinner=False)
def load_translation_model(src_lang="en", tgt_lang="hi"):
Â  Â  """Loads MarianMT translation model for src->tgt."""
Â  Â  pair = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
Â  Â  try:
Â  Â  Â  Â  tkn = MarianTokenizer.from_pretrained(pair)
Â  Â  Â  Â  m = MarianMTModel.from_pretrained(pair)
Â  Â  Â  Â  m.eval()
Â  Â  Â  Â  return tkn, m
Â  Â  except Exception:
Â  Â  Â  Â  return None, None

@st.cache_resource(show_spinner=False)
def load_sentiment_model(model_name="cardiffnlp/twitter-roberta-base-sentiment-latest"):
Â  Â  """Loads a sentiment analysis model."""
Â  Â  try:
Â  Â  Â  Â  tok = AutoTokenizer.from_pretrained(model_name)
Â  Â  Â  Â  m = AutoModelForSequenceClassification.from_pretrained(model_name)
Â  Â  Â  Â  m.eval()
Â  Â  Â  Â  return tok, m
Â  Â  except Exception:
Â  Â  Â  Â  return None, None

@st.cache_resource(show_spinner=False)
def load_tabular_models():
Â  Â  """Loads light scikit-learn models for demo."""
Â  Â  clf = Pipeline([("scaler", StandardScaler()), ("rf", RandomForestClassifier(n_estimators=50, random_state=42))])
Â  Â  reg = Pipeline([("scaler", StandardScaler()), ("rf", RandomForestRegressor(n_estimators=50, random_state=42))])
Â  Â  return clf, reg

# -------------------------
# Utility functions
# -------------------------
def text_classify(text: str, tokenizer, model, labels=None):
Â  Â  if tokenizer is None or model is None:
Â  Â  Â  Â  return {"label": "unknown", "score": 0.0}
Â  Â Â 
Â  Â  # Check if a model is suitable for sequence classification
Â  Â  if not hasattr(model, 'logits'):
Â  Â  Â  Â  # Corrected logic to handle models that don't directly output logits
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
Â  Â  Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  Â  Â  outputs = model(**inputs)
Â  Â  Â  Â  Â  Â  if hasattr(outputs, 'logits'):
Â  Â  Â  Â  Â  Â  Â  Â  logits = outputs.logits
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Fallback for models with different output formats
Â  Â  Â  Â  Â  Â  Â  Â  st.error("Model output format not supported. Could not find 'logits'.")
Â  Â  Â  Â  Â  Â  Â  Â  return {"label": "error", "score": 0.0}
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error during text classification: {e}")
Â  Â  Â  Â  return {"label": "error", "score": 0.0}
Â  Â  else:
Â  Â  Â  Â  # Original logic for models that directly output logits
Â  Â  Â  Â  inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
Â  Â  Â  Â  with torch.no_grad():
Â  Â  Â  Â  Â  Â  outputs = model(**inputs)
Â  Â  Â  Â  logits = outputs.logits

Â  Â  probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()[0]
Â  Â  pred = int(np.argmax(probs))
Â  Â Â 
Â  Â  if labels:
Â  Â  Â  Â  lbl = labels[pred]
Â  Â  else:
Â  Â  Â  Â  lbl = str(pred)
Â  Â  return {"label": lbl, "score": float(probs[pred])}


def translate_text(text: str, src: str, tgt: str):
Â  Â  tkn, m = load_translation_model(src, tgt)
Â  Â  if tkn is None or m is None:
Â  Â  Â  Â  return "Translation model not available for this pair; returning original text."
Â  Â Â 
Â  Â  inputs = tkn.prepare_seq2seq_batch([text], return_tensors="pt")
Â  Â  with torch.no_grad():
Â  Â  Â  Â  translated = m.generate(**inputs)
Â  Â  out = tkn.batch_decode(translated, skip_special_tokens=True)[0]
Â  Â  return out

def sentiment_text(text: str, tokenizer, model):
Â  Â  if tokenizer is None or model is None:
Â  Â  Â  Â  return {"label": "unknown", "score": 0.0}
Â  Â  inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
Â  Â  with torch.no_grad():
Â  Â  Â  Â  outputs = model(**inputs)
Â  Â  Â  Â  probs = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()[0]
Â  Â  Â  Â  pred_label = np.argmax(probs)
Â  Â  Â  Â  labels = ["Negative", "Neutral", "Positive"]
Â  Â  Â  Â  return {"label": labels[pred_label], "score": float(probs[pred_label])}

def preprocess_structured_input(data: Dict[str, Any]):
Â  Â  numeric_keys = ["age", "bmi", "sbp", "dbp", "glucose", "cholesterol"]
Â  Â  vals = []
Â  Â  for k in numeric_keys:
Â  Â  Â  Â  v = data.get(k, 0.0)
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  vals.append(float(v))
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  vals.append(0.0)
Â  Â  return np.array(vals).reshape(1, -1)

# -------------------------
# App UI: Sidebar + Navigation
# -------------------------
st.sidebar.title("HealthAI Suite")
menu = st.sidebar.radio("Select Module", [
Â  Â  "ðŸ§‘â€âš•ï¸ Risk Stratification",
Â  Â  "â± Length of Stay Prediction",
Â  Â  "ðŸ‘¥ Patient Segmentation",
Â  Â  "ðŸ©» Imaging Diagnostics",
Â  Â  "ðŸ“ˆ Sequence Forecasting",
Â  Â  "ðŸ“ Clinical Notes Analysis",
Â  Â  "ðŸŒ Translator",
Â  Â  "ðŸ’¬ Sentiment Analysis",
Â  Â  "ðŸ’¡ Chat Assistant"
])

text_tok, text_model = load_text_classifier()
sent_tok, sent_model = load_sentiment_model()
demo_clf, demo_reg = load_tabular_models()

# -------------------------
# Common patient form fields (used across pages)
# -------------------------
def patient_input_form(key_prefix="p"):
Â  Â  with st.form(key=f"form_{key_prefix}"):
Â  Â  Â  Â  col1, col2 = st.columns(2)
Â  Â  Â  Â  with col1:
Â  Â  Â  Â  Â  Â  age = st.number_input("Age", min_value=0, max_value=120, value=45, key=f"{key_prefix}_age")
Â  Â  Â  Â  Â  Â  gender = st.selectbox("Gender", ["Male", "Female", "Other"], key=f"{key_prefix}_gender")
Â  Â  Â  Â  Â  Â  bmi = st.number_input("BMI", min_value=10.0, max_value=60.0, value=25.0, key=f"{key_prefix}_bmi")
Â  Â  Â  Â  Â  Â  sbp = st.number_input("Systolic BP", min_value=60, max_value=250, value=120, key=f"{key_prefix}_sbp")
Â  Â  Â  Â  with col2:
Â  Â  Â  Â  Â  Â  dbp = st.number_input("Diastolic BP", min_value=40, max_value=160, value=80, key=f"{key_prefix}_dbp")
Â  Â  Â  Â  Â  Â  glucose = st.number_input("Glucose (mg/dL)", min_value=40, max_value=400, value=100, key=f"{key_prefix}_glucose")
Â  Â  Â  Â  Â  Â  cholesterol = st.number_input("Cholesterol (mg/dL)", min_value=100, max_value=500, value=180, key=f"{key_prefix}_cholesterol")
Â  Â  Â  Â  Â  Â  smoker = st.selectbox("Smoker", ["No", "Yes"], index=0, key=f"{key_prefix}_smoker")
Â  Â  Â  Â  submitted = st.form_submit_button("Run Analysis")
Â  Â  data = {
Â  Â  Â  Â  "age": int(age), "gender": gender, "bmi": float(bmi), "sbp": float(sbp), "dbp": float(dbp),
Â  Â  Â  Â  "glucose": float(glucose), "cholesterol": float(cholesterol), "smoker": smoker == "Yes"
Â  Â  }
Â  Â  return submitted, data

# -------------------------
# Module: Risk Stratification
# -------------------------
if menu == "ðŸ§‘â€âš•ï¸ Risk Stratification":
Â  Â  st.title("Risk Stratification")
Â  Â  st.write("Predict a patient's risk level based on key health indicators.")
Â  Â  submitted, pdata = patient_input_form("risk")
Â  Â  if submitted:
Â  Â  Â  Â  score = 0
Â  Â  Â  Â  score += (pdata['age'] >= 60) * 2 + (45 <= pdata['age'] < 60) * 1
Â  Â  Â  Â  score += (pdata['bmi'] >= 30) * 2 + (25 <= pdata['bmi'] < 30) * 1
Â  Â  Â  Â  score += (pdata['sbp'] >= 140) * 2 + (130 <= pdata['sbp'] < 140) * 1
Â  Â  Â  Â  score += (pdata['glucose'] >= 126) * 2 + (110 <= pdata['glucose'] < 126) * 1
Â  Â  Â  Â  score += (1 if pdata['smoker'] else 0)
Â  Â  Â  Â  label = "Low Risk" if score <= 1 else ("Moderate Risk" if score <= 3 else "High Risk")
Â  Â  Â  Â  st.success(f"Predicted Risk Level: *{label}* (Score: {score})")

# -------------------------
# Module: Patient Segmentation
# -------------------------
elif menu == "ðŸ‘¥ Patient Segmentation":
Â  Â  st.title("Patient Segmentation")
Â  Â  st.write("Assigns a patient to a distinct health cohort and visualizes their position relative to the groups.")
Â  Â  submitted, pdata = patient_input_form("seg")
Â  Â  if submitted:
Â  Â  Â  Â  X_new = preprocess_structured_input(pdata)

Â  Â  Â  Â  # Generate synthetic data for clustering
Â  Â  Â  Â  rng = np.random.RandomState(42)
Â  Â  Â  Â  synthetic_data = rng.normal(loc=[50,25,120,80,100,180], scale=[15,5,20,10,30,40], size=(200,6))

Â  Â  Â  Â  # Combine new patient data with synthetic data for clustering
Â  Â  Â  Â  X_all = np.vstack([synthetic_data, X_new])

Â  Â  Â  Â  scaler = StandardScaler()
Â  Â  Â  Â  Xs = scaler.fit_transform(X_all)

Â  Â  Â  Â  kmeans = KMeans(n_clusters=3, random_state=42, n_init=10).fit(Xs)
Â  Â  Â  Â  pred_label = kmeans.predict(Xs[-1].reshape(1, -1))[0]

Â  Â  Â  Â  # --- Visualization ---
Â  Â  Â  Â  st.success(f"Assigned Cohort: *Cohort {pred_label + 1}*")
Â  Â  Â  Â  st.write("The patient's profile is most similar to Cohort " + str(pred_label + 1) + ".")

Â  Â  Â  Â  st.subheader("Patient's Position within Cohorts")

Â  Â  Â  Â  # Use PCA for 2D visualization
Â  Â  Â  Â  pca = PCA(n_components=2)
Â  Â  Â  Â  X_pca = pca.fit_transform(Xs)

Â  Â  Â  Â  df_vis = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])
Â  Â  Â  Â  df_vis['Cohort'] = kmeans.labels_
Â  Â  Â  Â  df_vis['Cohort'] = df_vis['Cohort'].astype(str)
Â  Â  Â  Â  df_vis.loc[len(df_vis)-1, 'Cohort'] = 'New Patient'

Â  Â  Â  Â  fig, ax = plt.subplots(figsize=(8, 6))
Â  Â  Â  Â  cohort_colors = {0: 'blue', 1: 'green', 2: 'purple', 'New Patient': 'red'}

Â  Â  Â  Â  # Plot each cohort
Â  Â  Â  Â  for cohort_num in range(kmeans.n_clusters):
Â  Â  Â  Â  Â  Â  subset = df_vis[df_vis['Cohort'] == str(cohort_num)]
Â  Â  Â  Â  Â  Â  ax.scatter(subset['PCA1'], subset['PCA2'], alpha=0.7, label=f'Cohort {cohort_num+1}', color=cohort_colors[cohort_num])

Â  Â  Â  Â  # Plot the new patient
Â  Â  Â  Â  new_patient_point = df_vis[df_vis['Cohort'] == 'New Patient']
Â  Â  Â  Â  ax.scatter(new_patient_point['PCA1'], new_patient_point['PCA2'], marker='*', s=300, label='New Patient', color=cohort_colors['New Patient'], edgecolor='black')

Â  Â  Â  Â  ax.set_title("Patient Cohorts (2D PCA Visualization)")
Â  Â  Â  Â  ax.set_xlabel("Principal Component 1")
Â  Â  Â  Â  ax.set_ylabel("Principal Component 2")
Â  Â  Â  Â  ax.legend()
Â  Â  Â  Â  st.pyplot(fig)

Â  Â  Â  Â  # --- Cohort Characteristics ---
Â  Â  Â  Â  st.subheader("Cohort Characteristics")

Â  Â  Â  Â  # Create a DataFrame for average values of each cohort
Â  Â  Â  Â  cols = ["Age", "BMI", "SBP", "DBP", "Glucose", "Cholesterol"]
Â  Â  Â  Â  df_avg = pd.DataFrame(columns=cols)

Â  Â  Â  Â  for cohort_num in range(kmeans.n_clusters):
Â  Â  Â  Â  Â  Â  cluster_indices = np.where(kmeans.labels_ == cohort_num)[0]
Â  Â  Â  Â  Â  Â  avg_vals = np.mean(X_all[cluster_indices], axis=0)
Â  Â  Â  Â  Â  Â  df_avg.loc[f"Cohort {cohort_num+1}"] = avg_vals

Â  Â  Â  Â  st.dataframe(df_avg.style.format("{:.2f}"))
Â  Â  Â  Â  st.write("This table shows the average values for each key metric in each cohort.")

# -------------------------
# Module: Imaging Diagnostics
# -------------------------
elif menu == "ðŸ©» Imaging Diagnostics":
Â  Â  st.title("Imaging Diagnostics")
Â  Â  st.write("Simulates medical image analysis using a dummy model. In a full implementation, this would use a CNN for tasks like disease detection.")
Â  Â Â 
Â  Â  st.info("This is a placeholder module. A real-world application would require a trained Convolutional Neural Network (CNN) model and a proper image pre-processing pipeline.")
Â  Â Â 
Â  Â  uploaded_file = st.file_uploader("Upload a medical image (e.g., X-ray)", type=["png", "jpg", "jpeg"])
Â  Â  if uploaded_file:
Â  Â  Â  Â  st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  @st.cache_resource
Â  Â  Â  Â  def dummy_diagnose_image(image):
Â  Â  Â  Â  Â  Â  """A placeholder function for image diagnosis."""
Â  Â  Â  Â  Â  Â  # Simulate a diagnosis process
Â  Â  Â  Â  Â  Â  diag = np.random.choice(["No Anomaly Detected", "Pneumonia Detected", "Fracture Identified", "Mass Detected"], p=[0.7, 0.15, 0.1, 0.05])
Â  Â  Â  Â  Â  Â  confidence = np.random.uniform(0.7, 0.99)
Â  Â  Â  Â  Â  Â  return {"diagnosis": diag, "confidence": confidence}

Â  Â  Â  Â  if st.button("Run Diagnosis"):
Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing image..."):
Â  Â  Â  Â  Â  Â  Â  Â  # Pass the image to the dummy function
Â  Â  Â  Â  Â  Â  Â  Â  result = dummy_diagnose_image(uploaded_file)
Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Diagnosis Result: *{result['diagnosis']}* (Confidence: {result['confidence']:.2f})")
Â  Â  Â  Â  Â  Â  Â  Â Â 
# -------------------------
# Module: Sequence Forecasting
# -------------------------
elif menu == "ðŸ“ˆ Sequence Forecasting":
Â  Â  st.title("Sequence Forecasting")
Â  Â  st.write("Predicts a patient's next health metric value based on a time-series of past data.")

Â  Â  st.info("This is a simplified example. A full implementation would utilize a more sophisticated model like an LSTM or RNN.")

Â  Â  col1, col2 = st.columns(2)
Â  Â  with col1:
Â  Â  Â  Â  num_points = st.slider("Number of data points to generate", 5, 50, 15)
Â  Â  with col2:
Â  Â  Â  Â  noise_level = st.slider("Noise level", 0.0, 1.0, 0.1)

Â  Â  if st.button("Generate Data and Predict"):
Â  Â  Â  Â  # Generate synthetic time-series data
Â  Â  Â  Â  np.random.seed(42)
Â  Â  Â  Â  trend = np.linspace(50, 80, num_points)
Â  Â  Â  Â  noise = np.random.normal(0, noise_level * 10, num_points)
Â  Â  Â  Â  data = trend + noise

Â  Â  Â  Â  df_seq = pd.DataFrame({
Â  Â  Â  Â  Â  Â  "Time": range(1, num_points + 1),
Â  Â  Â  Â  Â  Â  "Metric Value": data
Â  Â  Â  Â  })

Â  Â  Â  Â  st.subheader("Generated Time-Series Data")
Â  Â  Â  Â  st.line_chart(df_seq.set_index("Time"))

Â  Â  Â  Â  # Simple prediction based on the last two points
Â  Â  Â  Â  last_two = data[-2:]
Â  Â  Â  Â  prediction = last_two[1] + (last_two[1] - last_two[0])

Â  Â  Â  Â  st.success(f"Based on the trend, the predicted next value is: *{prediction:.2f}*")
Â  Â  Â  Â  st.write("This prediction is made using a simple linear extrapolation from the last two data points.")

# -------------------------
# Module: Length of Stay Prediction
# -------------------------
elif menu == "â± Length of Stay Prediction":
Â  Â  st.title("Length of Stay Prediction")
Â  Â  st.write("Predicts the expected hospital length of stay (in days) for a patient.")
Â  Â  submitted, pdata = patient_input_form("los")
Â  Â  if submitted:
Â  Â  Â  Â  los_est = 3.0 + (pdata['age']/30.0) + (pdata['bmi']/40.0) + (pdata['glucose']/200.0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # This line rounds the prediction to the nearest whole number
Â  Â  Â  Â  los_est_rounded = int(round(los_est))
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.success(f"Predicted length of stay: *{los_est_rounded} days*")
Â  Â  Â  Â  st.info("The prediction is based on a simplified model. For a real-world application, a model fine-tuned on extensive patient data would be required.")

# -------------------------
# Module: Clinical Notes Analysis
# -------------------------
elif menu == "ðŸ“ Clinical Notes Analysis":
Â  Â  st.title("Clinical Notes Analysis")
Â  Â  st.write("Analyzes clinical notes to provide insights. The current model identifies emotional tone.")
Â  Â  notes = st.text_area("Paste clinical notes here", height=200, placeholder="Example: The patient presented with chest pain and a consistent cough.")
Â  Â  if st.button("Analyze Notes"):
Â  Â  Â  Â  if not notes.strip():
Â  Â  Â  Â  Â  Â  st.warning("Please paste clinical notes to analyze.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # We use a model that is suitable for sequence classification and outputs logits
Â  Â  Â  Â  Â  Â  # The previous version had an issue with the model.
Â  Â  Â  Â  Â  Â  res = text_classify(notes, text_tok, text_model, labels=["Anger", "Disgust", "Fear", "Joy", "Neutral", "Sadness", "Surprise"])
Â  Â  Â  Â  Â  Â  if res['label'] == 'error':
Â  Â  Â  Â  Â  Â  Â  Â  Â st.error("Failed to analyze notes. Check the model and input.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â st.success(f"Analysis: The note has a primary tone of *{res['label']}* (Confidence: {res['score']:.2f}).")


# -------------------------
# Module: Translator
# -------------------------
elif menu == "ðŸŒ Translator":
Â  Â  st.title("Translator")
Â  Â  st.write("Translate clinical or patient-facing text between different languages.")
Â  Â  col1, col2 = st.columns(2)
Â  Â  with col1:
Â  Â  Â  Â  src_lang = st.selectbox("Source Language", list(LANGUAGE_DICT.keys()), index=0)
Â  Â  with col2:
Â  Â  Â  Â  tgt_lang = st.selectbox("Target Language", list(LANGUAGE_DICT.keys()), index=1)
Â  Â Â 
Â  Â  text_to_trans = st.text_area("Text to translate", "Please describe your symptoms and any medications you are taking.", key="translator_input")
Â  Â Â 
Â  Â  if st.button("Translate"):
Â  Â  Â  Â  src_code = LANGUAGE_DICT.get(src_lang, "en")
Â  Â  Â  Â  tgt_code = LANGUAGE_DICT.get(tgt_lang, "en")
Â  Â  Â  Â Â 
Â  Â  Â  Â  with st.spinner("Translating..."):
Â  Â  Â  Â  Â  Â  translated_text = translate_text(text_to_trans, src_code, tgt_code)
Â  Â  Â  Â  Â  Â  st.success("Translated Text:")
Â  Â  Â  Â  Â  Â  st.write(translated_text)

# -------------------------
# Module: Sentiment Analysis
# -------------------------
elif menu == "ðŸ’¬ Sentiment Analysis":
Â  Â  st.title("Sentiment Analysis")
Â  Â  st.write("Analyzes the sentiment of patient feedback or reviews.")
Â  Â  txt = st.text_area("Paste patient feedback or reviews", "The nurse was very kind, but the waiting time was too long.", key="sentiment_input")
Â  Â  if st.button("Analyze Sentiment"):
Â  Â  Â  Â  res = sentiment_text(txt, sent_tok, sent_model)
Â  Â  Â  Â  st.success(f"Sentiment: *{res['label']}* (Confidence: {res['score']:.2f})")

# -------------------------
# Module: Chat Assistant
# -------------------------
elif menu == "ðŸ’¡ Chat Assistant":
Â  Â  st.title("Health Chat Assistant")
Â  Â  st.write("Ask questions and get information from a language model assistant.")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  together.api_key = st.secrets["TOGETHER_API_KEY"]
Â  Â  except KeyError:
Â  Â  Â  Â  st.error("Together API key not found in secrets.toml.")
Â  Â  Â  Â  together = None

Â  Â  if "messages" not in st.session_state:
Â  Â  Â  Â  st.session_state["messages"] = [
Â  Â  Â  Â  Â  Â  {"role": "assistant", "content": "Hello! I am a health assistant. How can I help you today?"}
Â  Â  Â  Â  ]

Â  Â  for msg in st.session_state.messages:
Â  Â  Â  Â  st.chat_message(msg["role"]).write(msg["content"])

Â  Â  if prompt := st.chat_input():
Â  Â  Â  Â  if not together:
Â  Â  Â  Â  Â  Â  st.chat_message("assistant").write("The chat assistant is not configured.")
Â  Â  Â  Â  Â  Â  st.stop()
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.session_state.messages.append({"role": "user", "content": prompt})
Â  Â  Â  Â  st.chat_message("user").write(prompt)

Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  with st.spinner("Thinking..."):
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chat_completion = together.Complete.create(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prompt=prompt,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model="mistralai/Mixtral-8x7B-Instruct-v0.1"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_response = chat_completion['choices'][0]['text']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "content": full_response})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(full_response)
Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Chatbot failed: {e}")
